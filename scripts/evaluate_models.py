#!/usr/bin/env python3
"""
06_evaluate_models_correct.py

CORRECT evaluation: Load previous stage's base + current stage's adapters
"""

import os
import sys
from pathlib import Path
import torch
import torch.nn.functional as F
from typing import List, Dict
import numpy as np
from tqdm import tqdm

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from transformers import AutoModel, AutoTokenizer

# Import adapter utils
import importlib.util
spec = importlib.util.spec_from_file_location(
    "eeve_adapter",
    PROJECT_ROOT / "scripts/utils/eeve_adapter.py"
)
eeve_adapter = importlib.util.module_from_spec(spec)
spec.loader.exec_module(eeve_adapter)
inject_adapters = eeve_adapter.inject_adapters


# Test dataset
SIMILAR_PAIRS = [
    ("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.", "ë‚ ì”¨ê°€ ë§¤ìš° í™”ì°½í•©ë‹ˆë‹¤."),
    ("ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆë‹¤.", "AI ê¸°ìˆ ì˜ ë°œì „ ì†ë„ê°€ ë¹ ë¥´ë‹¤."),
    ("ì €ëŠ” ì»¤í”¼ë¥¼ ë§¤ìš° ì¢‹ì•„í•©ë‹ˆë‹¤.", "ì»¤í”¼ë¥¼ ë§ˆì‹œëŠ” ê²ƒì„ ì •ë§ ì¦ê¹ë‹ˆë‹¤."),
    ("ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸í°ì„ ì¶œì‹œí–ˆë‹¤.", "ì‚¼ì„±ì´ ì‹ í˜• íœ´ëŒ€í°ì„ ê³µê°œí–ˆë‹¤."),
    ("ì´ ì˜í™”ëŠ” ì •ë§ ì¬ë¯¸ìˆì—ˆì–´ìš”.", "ì´ ì˜í™” ì§„ì§œ ì¬ë°Œì—ˆì–´ìš”."),
    ("ì£¼ì‹ ì‹œì¥ì´ ì˜¤ëŠ˜ í¬ê²Œ ìƒìŠ¹í–ˆë‹¤.", "ì˜¤ëŠ˜ ì¦ì‹œê°€ ê¸‰ë“±í–ˆë‹¤."),
    ("ê±´ê°•ì„ ìœ„í•´ ë§¤ì¼ ìš´ë™í•˜ê³  ìˆì–´ìš”.", "ê±´ê°• ê´€ë¦¬ë¥¼ ìœ„í•´ ë‚ ë§ˆë‹¤ ìš´ë™ ì¤‘ì´ì—ìš”."),
    ("ì´ ìŒì‹ì€ ë„ˆë¬´ ë§µìŠµë‹ˆë‹¤.", "ì´ ìš”ë¦¬ëŠ” ë§¤ìš° ë§µë„¤ìš”."),
    ("ì„œìš¸ì˜ êµí†µ ì²´ì¦ì´ ì‹¬ê°í•˜ë‹¤.", "ì„œìš¸ ì‹œë‚´ êµí†µ ì •ì²´ê°€ ë§¤ìš° ì‹¬í•˜ë‹¤."),
    ("íŒŒì´ì¬ì€ ë°°ìš°ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‹¤.", "íŒŒì´ì¬ì€ ì´ˆë³´ìê°€ í•™ìŠµí•˜ê¸° ì¢‹ì€ ì–¸ì–´ë‹¤."),
]

DIFFERENT_PAIRS = [
    ("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.", "ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ë¯¸ë˜ëŠ” ë°ë‹¤."),
    ("ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆë‹¤.", "ì €ëŠ” í”¼ìë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤."),
    ("ì €ëŠ” ì»¤í”¼ë¥¼ ë§¤ìš° ì¢‹ì•„í•©ë‹ˆë‹¤.", "í•œêµ­ì˜ ê²½ì œ ì„±ì¥ë¥ ì´ ë‘”í™”ë˜ê³  ìˆë‹¤."),
    ("ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸í°ì„ ì¶œì‹œí–ˆë‹¤.", "ê³ ì–‘ì´ëŠ” ê·€ì—¬ìš´ ë™ë¬¼ì´ë‹¤."),
    ("ì´ ì˜í™”ëŠ” ì •ë§ ì¬ë¯¸ìˆì—ˆì–´ìš”.", "ìˆ˜í•™ ê³µì‹ì„ ì™¸ìš°ëŠ” ê²ƒì´ ì–´ë µë‹¤."),
    ("ì£¼ì‹ ì‹œì¥ì´ ì˜¤ëŠ˜ í¬ê²Œ ìƒìŠ¹í–ˆë‹¤.", "ë°”ë‹¤ì—ì„œ ì„œí•‘ì„ ì¦ê¸°ê³  ìˆì–´ìš”."),
    ("ê±´ê°•ì„ ìœ„í•´ ë§¤ì¼ ìš´ë™í•˜ê³  ìˆì–´ìš”.", "ìë™ì°¨ ê°€ê²©ì´ ê³„ì† ì˜¤ë¥´ê³  ìˆë‹¤."),
    ("ì´ ìŒì‹ì€ ë„ˆë¬´ ë§µìŠµë‹ˆë‹¤.", "ì¸í„°ë„· ì†ë„ê°€ ë§¤ìš° ë¹ ë¥´ë‹¤."),
    ("ì„œìš¸ì˜ êµí†µ ì²´ì¦ì´ ì‹¬ê°í•˜ë‹¤.", "ì‹ë¬¼ì— ë¬¼ì„ ì£¼ëŠ” ê²ƒì„ ìŠì—ˆë‹¤."),
    ("íŒŒì´ì¬ì€ ë°°ìš°ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‹¤.", "ì—¬ë¦„ íœ´ê°€ë¥¼ ì œì£¼ë„ì—ì„œ ë³´ëƒˆë‹¤."),
]


def load_model_and_tokenizer(
    model_path: str,
    base_model_path: str = None,
    load_adapters: bool = False,
    adapter_type: str = "bottleneck"
):
    """
    CORRECT model loading:
    - For adapter stages: Load BASE from previous stage, inject adapters, load adapter weights from current stage
    """
    print(f"Loading model from: {model_path}")

    if not load_adapters:
        # Non-adapter stages (Stage 0, Stage 1)
        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            model_path,
            trust_remote_code=True,
            torch_dtype=torch.bfloat16
        )
    else:
        # Adapter stages (Stage 2, Stage 3)
        print(f"  Base model: {base_model_path}")
        print(f"  Adapter type: {adapter_type}")

        # Load BASE model from previous stage
        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            base_model_path,  # Load from PREVIOUS stage!
            trust_remote_code=True,
            torch_dtype=torch.bfloat16
        )

        # Inject adapter structure
        print(f"  Injecting {adapter_type} adapters...")
        model = inject_adapters(
            model,
            adapter_type=adapter_type,
            adapter_size=256,
            dropout=0.1,
            layer_indices=None
        )

        # Load adapter weights from CURRENT stage
        print(f"  Loading adapter weights from {model_path}...")
        from safetensors import safe_open
        state_dict = {}
        safetensors_path = Path(model_path) / "model.safetensors"

        with safe_open(str(safetensors_path), framework="pt", device="cpu") as f:
            for key in f.keys():
                if 'adapter' in key:
                    state_dict[key] = f.get_tensor(key)

        missing, unexpected = model.load_state_dict(state_dict, strict=False)
        print(f"  âœ“ Loaded {len(state_dict)} adapter parameters")

    model.eval()
    model = model.cuda()
    return model, tokenizer


def mean_pooling(hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()
    sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)
    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)
    return sum_embeddings / sum_mask


def get_embeddings(texts: List[str], model, tokenizer, max_length: int = 512) -> torch.Tensor:
    inputs = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors="pt")
    inputs = {k: v.cuda() for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs, output_hidden_states=True)
        hidden_states = outputs.hidden_states[-1]
        embeddings = mean_pooling(hidden_states, inputs['attention_mask'])
        embeddings = F.normalize(embeddings, p=2, dim=1)

    return embeddings


def compute_similarity(emb1: torch.Tensor, emb2: torch.Tensor) -> float:
    return F.cosine_similarity(emb1, emb2, dim=1).item()


def evaluate_model(model, tokenizer, model_name: str) -> Dict[str, float]:
    print(f"\n{'='*80}")
    print(f"Evaluating: {model_name}")
    print('='*80)

    similar_scores = []
    different_scores = []

    print("\n[ìœ ì‚¬í•œ ë¬¸ì¥ ìŒ]")
    for sent1, sent2 in tqdm(SIMILAR_PAIRS, desc="Similar pairs"):
        emb1 = get_embeddings([sent1], model, tokenizer)
        emb2 = get_embeddings([sent2], model, tokenizer)
        score = compute_similarity(emb1, emb2)
        similar_scores.append(score)
        print(f"  Score: {score:.4f} | {sent1[:30]}... <-> {sent2[:30]}...")

    print("\n[ë‹¤ë¥¸ ë¬¸ì¥ ìŒ]")
    for sent1, sent2 in tqdm(DIFFERENT_PAIRS, desc="Different pairs"):
        emb1 = get_embeddings([sent1], model, tokenizer)
        emb2 = get_embeddings([sent2], model, tokenizer)
        score = compute_similarity(emb1, emb2)
        different_scores.append(score)
        print(f"  Score: {score:.4f} | {sent1[:30]}... <-> {sent2[:30]}...")

    avg_similar = np.mean(similar_scores)
    avg_different = np.mean(different_scores)
    separation = avg_similar - avg_different

    print(f"\n{'='*80}")
    print(f"Results for {model_name}:")
    print(f"  ìœ ì‚¬ ë¬¸ì¥ í‰ê·  ì ìˆ˜: {avg_similar:.4f} (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"  ë‹¤ë¥¸ ë¬¸ì¥ í‰ê·  ì ìˆ˜: {avg_different:.4f} (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"  êµ¬ë¶„ë„ (Separation): {separation:.4f} (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print('='*80)

    return {
        'avg_similar': avg_similar,
        'avg_different': avg_different,
        'separation': separation,
        'similar_scores': similar_scores,
        'different_scores': different_scores
    }


def main():
    print("="*80)
    print("í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í‰ê°€ (CORRECT)")
    print("="*80)

    # Model configurations with base_model_path for adapter stages
    models = [
        {
            "name": "Stage 0 (Vocab Expanded)",
            "path": str(PROJECT_ROOT / "outputs/koqwen-expanded"),
            "load_adapters": False,
        },
        {
            "name": "Stage 1 v2 (SimCSE 10K)",
            "path": str(PROJECT_ROOT / "checkpoints/stage1/final"),
            "load_adapters": False,
        },
        {
            "name": "Stage 2 (EEVE Adapter)",
            "path": str(PROJECT_ROOT / "checkpoints/stage2/final"),
            "base_model_path": str(PROJECT_ROOT / "checkpoints/stage1/final"),  # Load Stage 1 base!
            "load_adapters": True,
            "adapter_type": "bottleneck",
        },
        {
            "name": "Stage 3 (Hierarchical)",
            "path": str(PROJECT_ROOT / "checkpoints/stage3/final"),
            "base_model_path": str(PROJECT_ROOT / "checkpoints/stage1/final"),  # Load Stage 1 base! (Stage 3 replaces Stage 2 adapters)
            "load_adapters": True,
            "adapter_type": "hierarchical",
        },
    ]

    results = {}

    for config in models:
        if not Path(config["path"]).exists():
            print(f"\nâš ï¸  ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config['path']}")
            continue

        try:
            model, tokenizer = load_model_and_tokenizer(
                config["path"],
                base_model_path=config.get("base_model_path"),
                load_adapters=config.get("load_adapters", False),
                adapter_type=config.get("adapter_type", "bottleneck")
            )

            result = evaluate_model(model, tokenizer, config["name"])
            results[config["name"]] = result

            del model, tokenizer
            torch.cuda.empty_cache()

        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {config['name']}")
            print(f"   {str(e)}")
            import traceback
            traceback.print_exc()
            continue

    # Final comparison
    print("\n" + "="*80)
    print("ìµœì¢… ë¹„êµ ê²°ê³¼")
    print("="*80)
    print(f"{'Model':<30} {'Similarâ†‘':<12} {'Differentâ†“':<12} {'Separationâ†‘':<12}")
    print("-"*80)

    for model_name, result in results.items():
        print(f"{model_name:<30} "
              f"{result['avg_similar']:<12.4f} "
              f"{result['avg_different']:<12.4f} "
              f"{result['separation']:<12.4f}")

    print("="*80)

    if results:
        best_model = max(results.items(), key=lambda x: x[1]['separation'])
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model[0]}")
        print(f"   êµ¬ë¶„ë„: {best_model[1]['separation']:.4f}")
        print("="*80)


if __name__ == "__main__":
    main()
