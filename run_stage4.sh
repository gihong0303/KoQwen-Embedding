#!/usr/bin/env bash
# Stage 4: Full Vocabulary Harmonization

set -euo pipefail

export CUDA_VISIBLE_DEVICES=2,3,4,5,6,7,8,9
export TOKENIZERS_PARALLELISM=false
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1
export NCCL_SHM_DISABLE=1
export TORCH_NCCL_BLOCKING_WAIT=1
export CUDA_DEVICE_MAX_CONNECTIONS=1
export NCCL_DEBUG=WARN
export NCCL_SOCKET_FAMILY=AF_INET

MODEL_PATH="checkpoints/stage3/final"
NUM_GPUS=8

echo "================================================================================"
echo "üéØ Stage 4: Full Vocabulary Harmonization"
echo "================================================================================"
echo ""
echo "ÌïôÏäµ ÎåÄÏÉÅ: embed_tokens (Ï†ÑÏ≤¥ ÌÜ†ÌÅ∞!)"
echo "Îç∞Ïù¥ÌÑ∞: Mixed Dataset (200K)"
echo "  - KOREAN-WEBTEXT: 100K"
echo "  - KOREAN-SyntheticText: 80K"
echo "  - KoSimpleEval: 20K"
echo "ÏûÖÎ†•: ${MODEL_PATH}"
echo "GPUs: ${CUDA_VISIBLE_DEVICES}"
echo "Î∞∞Ïπò: 10 √ó 6 √ó 8 = 480 (effective batch size)"
echo ""
echo "‚ö†Ô∏è  Ï£ºÏùò: Ïù¥ Îã®Í≥ÑÎ∂ÄÌÑ∞ Í∏∞Ï°¥ ÌÜ†ÌÅ∞ÎèÑ ÌïôÏäµÌï©ÎãàÎã§!"
echo ""
echo "================================================================================"
echo ""

torchrun \
  --nproc_per_node=${NUM_GPUS} \
  --master_addr=127.0.0.1 \
  --master_port=29534 \
  scripts/stage4.py \
  --config configs/pipeline_config.yaml \
  --model_path "${MODEL_PATH}" \
  --seed 42

echo ""
echo "‚úÖ Stage 4 ÏôÑÎ£å! ‚Üí checkpoints/stage4/final"
echo ""
