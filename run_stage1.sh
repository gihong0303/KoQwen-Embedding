#!/usr/bin/env bash
# Stage 1: New Token Input Embeddings

set -euo pipefail

export CUDA_VISIBLE_DEVICES=2,3,4,5,6,7,8,9
export TOKENIZERS_PARALLELISM=false
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1
export NCCL_SHM_DISABLE=1
export TORCH_NCCL_BLOCKING_WAIT=1
export CUDA_DEVICE_MAX_CONNECTIONS=1
export NCCL_DEBUG=WARN
export NCCL_SOCKET_FAMILY=AF_INET

NUM_GPUS=8

echo "================================================================================"
echo "ğŸ¯ Stage 1: New Token Input Embeddings (ìµœì í™” - 8 GPUs)"
echo "================================================================================"
echo ""
echo "í•™ìŠµ ëŒ€ìƒ: embed_tokens (ìƒˆ í† í° 67,762ê°œë§Œ)"
echo "ë°ì´í„°: KOREAN-WEBTEXT (300K)"
echo "GPUs: ${CUDA_VISIBLE_DEVICES}"
echo "ë°°ì¹˜: 20 Ã— 3 Ã— 8 = 480 (effective batch size)"
echo "ì˜ˆìƒ ì‹œê°„: ~2-2.5ì‹œê°„ (ê¸°ì¡´ 4ì‹œê°„ â†’ 50% ë‹¨ì¶•)"
echo ""
echo "================================================================================"
echo ""

torchrun \
  --nproc_per_node=${NUM_GPUS} \
  --master_addr=127.0.0.1 \
  --master_port=29531 \
  scripts/stage1.py \
  --config configs/pipeline_config.yaml \
  --seed 42

echo ""
echo "âœ… Stage 1 ì™„ë£Œ! â†’ checkpoints/stage1/final"
echo ""
